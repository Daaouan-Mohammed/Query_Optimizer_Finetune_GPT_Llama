{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e77e94-a5ee-4e86-bc1d-d4f652d04953",
   "metadata": {},
   "source": [
    "# OpenAI Fine-tuning API \"Neo Optimizer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a1d4f-8d1f-4b95-a5e6-4ab8d4ae5e17",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0441db10-1aa1-4877-949e-166636bf145a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import csv\n",
    "import json\n",
    "import random\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66ad59d-91a3-4d37-9599-034c7382244b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Downloading dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install backend dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [50 lines of output]\n",
      "  Collecting distribute\n",
      "    WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000274E89D8FE0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/5f/ad/1fde06877a8d7d5c9b60eff7de2d452f639916ae1d48f0b8f97bf97e570a/distribute-0.7.3.zip\n",
      "    Downloading distribute-0.7.3.zip (145 kB)\n",
      "       ---------------------------------------- 0.0/145.4 kB ? eta -:--:--\n",
      "       -- ------------------------------------- 10.2/145.4 kB ? eta -:--:--\n",
      "       -- ------------------------------------- 10.2/145.4 kB ? eta -:--:--\n",
      "       -- ------------------------------------- 10.2/145.4 kB ? eta -:--:--\n",
      "       -- ------------------------------------- 10.2/145.4 kB ? eta -:--:--\n",
      "       -- ------------------------------------- 10.2/145.4 kB ? eta -:--:--\n",
      "       ------- ----------------------------- 30.7/145.4 kB 119.1 kB/s eta 0:00:01\n",
      "       ------- ----------------------------- 30.7/145.4 kB 119.1 kB/s eta 0:00:01\n",
      "       ---------- -------------------------- 41.0/145.4 kB 115.5 kB/s eta 0:00:01\n",
      "       --------------- --------------------- 61.4/145.4 kB 156.1 kB/s eta 0:00:01\n",
      "       --------------- --------------------- 61.4/145.4 kB 156.1 kB/s eta 0:00:01\n",
      "       ----------------------- ------------- 92.2/145.4 kB 201.8 kB/s eta 0:00:01\n",
      "       --------------------------- -------- 112.6/145.4 kB 233.8 kB/s eta 0:00:01\n",
      "       ------------------------------ ----- 122.9/145.4 kB 240.2 kB/s eta 0:00:01\n",
      "       ------------------------------------ 145.4/145.4 kB 261.9 kB/s eta 0:00:00\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    Preparing metadata (pyproject.toml) did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    [6 lines of output]\n",
      "    usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "       or: setup.py --help [cmd1 cmd2 ...]\n",
      "       or: setup.py --help-commands\n",
      "       or: setup.py cmd --help\n",
      "  \n",
      "    error: invalid command 'dist_info'\n",
      "    [end of output]\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  error: metadata-generation-failed\n",
      "  \n",
      "  Encountered error while generating package metadata.\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This is an issue with the package mentioned above, not pip.\n",
      "  hint: See above for details.\n",
      "  \n",
      "  [notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "  [notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install backend dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae0f70-7224-44f7-b0ff-39ea3e6498c0",
   "metadata": {},
   "source": [
    "### create client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2050a44a-ebca-4dd7-8214-2377b3b5db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f83c2c9-34bd-4035-8b89-b4892d3803c6",
   "metadata": {},
   "source": [
    "### prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01e0af20-a91a-4845-85f2-6ab967247c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv of YouTube comments\n",
    "\n",
    "query_list = []\n",
    "optimized_query_list = []\n",
    "\n",
    "with open('dataDataSet.csv', mode ='r') as file:\n",
    "    file = csv.reader(file)\n",
    "    \n",
    "    # read file line by line\n",
    "    for line in file:\n",
    "        # skip first line\n",
    "        if line[0]=='query':\n",
    "            continue\n",
    "            \n",
    "        # append comments and responses to respective lists\n",
    "        query_list.append(line[0])\n",
    "        optimized_query_list.append(line[1] + \" -ShawGPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "032ea2f8-cdcb-49ab-9686-539306650403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7464c42-988f-4fea-937a-5d54f3c3b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct training examples\n",
    "example_list = []\n",
    "\n",
    "intstructions_string_few_shot = \"\"\"ShawGPT, You are a chatbot specializing in optimizing SQL queries within the Oracle syntax ecosystem. Your primary functionality is to receive SQL queries from users and provide them with optimized versions for better performance. \\\n",
    "\n",
    "Here are examples of ShawGPT responding to queries.\n",
    "\n",
    "query: SELECT * FROM Professor WHERE first_name = 'John';\n",
    "ShawGPT: SELECT professor_id, last_name FROM Professor WHERE first_name = 'John' INDEX(first_name);  -ShawGPT\n",
    "\n",
    "query: SELECT * FROM Course WHERE course_code = 'MATH101';\n",
    "ShawGPT: SELECT course_id, course_name, credit_hours FROM Course WHERE course_code = 'MATH101' INDEX(course_code);  -ShawGPT\n",
    "\n",
    "query: SELECT * FROM Enrollment WHERE student_id IN (10, 20, 30);\n",
    "ShawGPT: SELECT course_id FROM Enrollment WHERE student_id IN (10, 20, 30) INDEX(student_id); -ShawGPT\"\"\"\n",
    "\n",
    "for i in range(len(query_list)):    \n",
    "    system_dict = {\"role\": \"system\", \"content\": intstructions_string_few_shot}\n",
    "    user_dict = {\"role\": \"user\", \"content\": query_list[i]}\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": optimized_query_list[i]}\n",
    "    \n",
    "    messages_list = [system_dict, user_dict, assistant_dict]\n",
    "    \n",
    "    example_list.append({\"messages\": messages_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86095500-368c-4038-9607-ef81756d7af0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create train/validation split\n",
    "validation_index_list = random.sample(range(0, len(example_list)-1), 9)\n",
    "\n",
    "validation_data_list = [example_list[index] for index in validation_index_list]\n",
    "\n",
    "for example in validation_data_list:\n",
    "    example_list.remove(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "efecacf8-78cd-4138-bbdc-d1a904498371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write examples to file\n",
    "with open('data/training-data.jsonl', 'w') as training_file:\n",
    "    for example in example_list:\n",
    "        json.dump(example, training_file)\n",
    "        training_file.write('\\n')\n",
    "\n",
    "with open('data/validation-data.jsonl', 'w') as validation_file:\n",
    "    for example in validation_data_list:\n",
    "        json.dump(example, validation_file)\n",
    "        validation_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb1d91-e09d-4e62-85d6-e1c752713b73",
   "metadata": {},
   "source": [
    "### upload training examples to openai api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9acc14a1-eced-48b4-b9f6-1b6fd761502d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_file = client.files.create(\n",
    "  file = open(\"data/training-data.jsonl\", \"rb\"),\n",
    "  purpose = \"fine-tune\"\n",
    ")\n",
    "\n",
    "validation_file = client.files.create(\n",
    "  file = open(\"data/validation-data.jsonl\", \"rb\"),\n",
    "  purpose = \"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc40bd-6296-425d-bb0c-564682ed6fcd",
   "metadata": {},
   "source": [
    "### create a fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db1090c8-fa58-4fb0-9f73-626cb2aaeeb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-zbSaFTFwBvPjjZPTh4Sj4Zgo', created_at=1707660200, error=Error(code=None, message=None, param=None, error=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-K9BB640pBH3H5vq7s9XXo0zd', result_files=[], status='validating_files', trained_tokens=None, training_file='file-tyf1U4QNbQqH34aADKIBTUPu', validation_file='file-Y4Sn2L90xwlmL1miMFjUWxNO')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.create(\n",
    "    training_file = training_file.id,\n",
    "    validation_file = validation_file.id,\n",
    "    suffix = \"ShawGPT\",\n",
    "    model = \"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a18db72-569e-428c-ad63-c32252ca1a1c",
   "metadata": {},
   "source": [
    "### use fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c63f203-3e21-4acf-a5ed-82081b9c6a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_query = \"\"\"SELECT employees.employee_id, employees.first_name, employees.last_name, departments.department_name\n",
    "FROM employees\n",
    "JOIN departments ON employees.department_id = departments.department_id\n",
    "WHERE employees.salary > 50000;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "573b43f4-5fd9-40e9-8f98-7bb5ced1b0ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\"role\": \"system\", \"content\": intstructions_string_few_shot},\n",
    "    {\"role\": \"user\", \"content\": test_query}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "380a16c1-312d-4b1a-b2a8-ad9f69eb9193",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query you provided looks fine. However, it could benefit from an index on the \"salary\" column of the \"employees\" table to improve performance. Here's the optimized version:\n",
      "\n",
      "SELECT employees.employee_id, employees.first_name, employees.last_name, departments.department_name\n",
      "FROM employees INDEX(salary)\n",
      "JOIN departments ON employees.department_id = departments.department_id\n",
      "WHERE employees.salary > 50000;\n",
      "\n",
      "Adding INDEX(salary) ensures that the database engine uses an index scan on the \"salary\" column, which can speed up the query execution.\n"
     ]
    }
   ],
   "source": [
    "print(dict(response)['choices'][0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a31205-59f9-4ffd-9012-9dc41a94caff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete file\n",
    "# client.files.delete(training_file.id)\n",
    "# client.files.delete(validation_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978b7a59-a801-4083-b028-587071b13ed3",
   "metadata": {},
   "source": [
    "### More resources\n",
    "\n",
    "OpenAI Guide: https://platform.openai.com/docs/guides/fine-tuning <br>\n",
    "Fine-tuning doc: https://platform.openai.com/docs/api-reference/fine-tuning <br>\n",
    "Fine-tuning data prep: https://cookbook.openai.com/examples/chat_finetuning_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4a00ba-2a9d-4a8f-aad6-6949fb86d2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
